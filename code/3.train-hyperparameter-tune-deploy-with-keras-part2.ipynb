{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Copyright (c) Microsoft Corporation. All rights reserved.\n\nLicensed under the MIT License."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/MachineLearningNotebooks/how-to-use-azureml/training-with-deep-learning/train-hyperparameter-tune-deploy-with-keras/train-hyperparameter-tune-deploy-with-keras.png)"
    },
    {
      "metadata": {
        "nbpresent": {
          "id": "bf74d2e9-2708-49b1-934b-e0ede342f475"
        }
      },
      "cell_type": "markdown",
      "source": "# Training, hyperparameter tune, and deploy with Keras (Part 2)\n\n## Introduction\nThis tutorial shows how to train a simple deep neural network using the MNIST dataset and Keras on Azure Machine Learning. MNIST is a popular dataset consisting of 70,000 grayscale images. Each image is a handwritten digit of `28x28` pixels, representing number from 0 to 9. The goal is to create a multi-class classifier to identify the digit each image represents, and deploy it as a web service in Azure.\n\nFor more information about the MNIST dataset, please visit [Yan LeCun's website](http://yann.lecun.com/exdb/mnist/).\n\n## Prerequisite:\n* Understand the [architecture and terms](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture) introduced by Azure Machine Learning\n* If you are using an Azure Machine Learning Notebook VM, you are all set. Otherwise, go through the [configuration notebook](../../../configuration.ipynb) to:\n    * install the AML SDK\n    * create a workspace and its configuration file (`config.json`)\n* For local scoring test, you will also need to have `tensorflow` and `keras` installed in the current Jupyter kernel."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Let's get started. First let's import some Python libraries."
    },
    {
      "metadata": {
        "nbpresent": {
          "id": "c377ea0c-0cd9-4345-9be2-e20fb29c94c3"
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "%matplotlib inline\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "nbpresent": {
          "id": "edaa7f2f-2439-4148-b57a-8c794c0945ec"
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "import azureml\nfrom azureml.core import Workspace\n\n# check core SDK version number\nprint(\"Azure ML SDK Version: \", azureml.core.VERSION)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Initialize workspace\nInitialize a [Workspace](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#workspace) object from the existing workspace you created in the Prerequisites step. `Workspace.from_config()` creates a workspace object from the details stored in `config.json`."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "ws = Workspace.from_config()\nprint('Workspace name: ' + ws.name, \n      'Azure region: ' + ws.location, \n      'Subscription id: ' + ws.subscription_id, \n      'Resource group: ' + ws.resource_group, sep='\\n')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Loading MNIST test dataset and models\nIn order to test the MNIST dataset we will need to load it from local folder named `data` that was created in part 1. Also, we need to recall the model that was created in part 1. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from utils import load_data\nfrom azureml.core.model import Model\n\nX_test = load_data('./data/mnist/test-images.gz', False) / 255.0\ny_test = load_data('./data/mnist/test-labels.gz', True).reshape(-1)\nmodel = Model(ws, 'keras-mlp-mnist')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Deploy the model in ACI\nNow we are ready to deploy the model as a web service running in Azure Container Instance [ACI](https://azure.microsoft.com/en-us/services/container-instances/). Azure Machine Learning accomplishes this by constructing a Docker image with the scoring logic and model baked in.\n### Create score.py\nFirst, we will create a scoring script that will be invoked by the web service call. \n\n* Note that the scoring script must have two required functions, `init()` and `run(input_data)`. \n  * In `init()` function, you typically load the model into a global object. This function is executed only once when the Docker container is started. \n  * In `run(input_data)` function, the model is used to predict a value based on the input data. The input and output to `run` typically use JSON as serialization and de-serialization format but you are not limited to that."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%%writefile score.py\nimport json\nimport numpy as np\nimport os\nfrom keras.models import model_from_json\n\nfrom azureml.core.model import Model\n\ndef init():\n    global model\n    \n    model_root = Model.get_model_path('keras-mlp-mnist')\n    # load json and create model\n    json_file = open(os.path.join(model_root, 'model.json'), 'r')\n    model_json = json_file.read()\n    json_file.close()\n    model = model_from_json(model_json)\n    # load weights into new model\n    model.load_weights(os.path.join(model_root, \"model.h5\"))   \n    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n    \ndef run(raw_data):\n    data = np.array(json.loads(raw_data)['data'])\n    # make prediction\n    y_hat = np.argmax(model.predict(data), axis=1)\n    return y_hat.tolist()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Create myenv.yml\nWe also need to create an environment file so that Azure Machine Learning can install the necessary packages in the Docker image which are required by your scoring script. In this case, we need to specify conda packages `tensorflow` and `keras`."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core.runconfig import CondaDependencies\n\ncd = CondaDependencies.create()\ncd.add_conda_package('tensorflow')\ncd.add_conda_package('keras')\ncd.save_to_file(base_directory='./', conda_file_path='myenv.yml')\n\nprint(cd.serialize_to_string())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Deploy to ACI\nWe are almost ready to deploy. Create a deployment configuration and specify the number of CPUs and gigbyte of RAM needed for your ACI container. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core.webservice import AciWebservice\n\naciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n                                               auth_enabled=True, # this flag generates API keys to secure access\n                                               memory_gb=1, \n                                               tags={'name':'mnist', 'framework': 'Keras'},\n                                               description='Keras MLP on MNIST')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Deployment Process\nNow we can deploy. **This cell will run for about 7-8 minutes**. Behind the scene, it will do the following:\n1. **Build Docker image**  \nBuild a Docker image using the scoring file (`score.py`), the environment file (`myenv.yml`), and the `model` object. \n2. **Register image**    \nRegister that image under the workspace. \n3. **Ship to ACI**    \nAnd finally ship the image to the ACI infrastructure, start up a container in ACI using that image, and expose an HTTP endpoint to accept REST client calls."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core.image import ContainerImage\n\nimgconfig = ContainerImage.image_configuration(execution_script=\"score.py\", \n                                               runtime=\"python\", \n                                               conda_file=\"myenv.yml\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%%time\nfrom azureml.core.webservice import Webservice\n\nservice = Webservice.deploy_from_model(workspace=ws,\n                                       name='keras-mnist-svc',\n                                       deployment_config=aciconfig,\n                                       models=[model],\n                                       image_config=imgconfig)\n\nservice.wait_for_deployment(show_output=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "**Tip: If something goes wrong with the deployment, the first thing to look at is the logs from the service by running the following command:**"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(service.get_logs())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "This is the scoring web service endpoint:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(service.scoring_uri)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Test the deployed model\nLet's test the deployed model. Pick 30 random samples from the test set, and send it to the web service hosted in ACI. Note here we are using the `run` API in the SDK to invoke the service. You can also make raw HTTP calls using any HTTP tool such as curl.\n\nAfter the invocation, we print the returned predictions and plot them along with the input images. Use red font color and inversed image (white on black) to highlight the misclassified samples. Note since the model accuracy is pretty high, you might have to run the below cell a few times before you can see a misclassified sample."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import json\n\n# find 30 random samples from test set\nn = 30\nsample_indices = np.random.permutation(X_test.shape[0])[0:n]\n\ntest_samples = json.dumps({\"data\": X_test[sample_indices].tolist()})\ntest_samples = bytes(test_samples, encoding='utf8')\n\n# predict using the deployed model\nresult = service.run(input_data=test_samples)\ny_hat = result\n\n# compare actual value vs. the predicted values:\ni = 0\nplt.figure(figsize = (20, 1))\n\nfor s in sample_indices:\n    plt.subplot(1, n, i + 1)\n    plt.axhline('')\n    plt.axvline('')\n    \n    # use different color for misclassified sample\n    font_color = 'red' if y_test[s] != result[i] else 'black'\n    clr_map = plt.cm.gray if y_test[s] != result[i] else plt.cm.Greys\n    \n    plt.text(x=10, y=-10, s=y_hat[i], fontsize=18, color=font_color)\n    plt.imshow(X_test[s].reshape(28, 28), cmap=clr_map)\n    \n    i = i + 1\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We can retreive the API keys used for accessing the HTTP endpoint."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# retreive the API keys. two keys were generated.\nkey1, Key2 = service.get_keys()\nprint(key1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We can now send construct raw HTTP request and send to the service. Don't forget to add key to the HTTP header."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import requests\n\n# send a random row from the test set to score\nrandom_index = np.random.randint(0, len(X_test)-1)\ninput_data = \"{\\\"data\\\": [\" + str(list(X_test[random_index])) + \"]}\"\n\nheaders = {'Content-Type':'application/json', 'Authorization': 'Bearer ' + key1}\n\nresp = requests.post(service.scoring_uri, input_data, headers=headers)\n\nprint(\"POST to url\", service.scoring_uri)\n#print(\"input data:\", input_data)\nprint(\"label:\", y_test[random_index])\nprint(\"prediction:\", resp.text)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Let's look at the workspace after the web service was deployed. You should see \n* a registered model named 'keras-mlp-mnist' and with the id 'model:1'\n* an image called 'keras-mnist-svc' and with a docker image location pointing to your workspace's Azure Container Registry (ACR)  \n* a webservice called 'keras-mnist-svc' with some scoring URL"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "models = ws.models\nfor name, model in models.items():\n    print(\"Model: {}, ID: {}\".format(name, model.id))\n    \nimages = ws.images\nfor name, image in images.items():\n    print(\"Image: {}, location: {}\".format(name, image.image_location))\n    \nwebservices = ws.webservices\nfor name, webservice in webservices.items():\n    print(\"Webservice: {}, scoring URI: {}\".format(name, webservice.scoring_uri))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Clean up\nYou can delete the ACI deployment with a simple delete API call."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "service.delete()",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "authors": [
      {
        "name": "maxluk"
      }
    ],
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    },
    "msauthor": "maxluk"
  },
  "nbformat": 4,
  "nbformat_minor": 2
}